{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"],"fields":{"title":{"boost":1000.0},"text":{"boost":1.0},"tags":{"boost":1000000.0}}},"docs":[{"location":"","title":"ARBA: Returning to the Fundamentals of Search","text":"<p>Automation is the Engine, but Ad Rank is the Key. Master your Quality Score to unlock the full potential of your Search campaigns.</p>"},{"location":"#the-reality-of-modern-search","title":"The Reality of Modern Search","text":"<p>It is a common misconception that combining a larger budget with AI equals guaranteed wins. The reality is that automation without relevance is simply an expensive way to lose auctions faster. Tools like Broad Match and Exploration Bidding are built to find volume and coverage; they are not designed to fix poor quality. The hard truth is that Ad Rank remains the gatekeeper. Google's auction continues to prioritize the user experience, meaning no amount of AI can bypass the core formula. You still have to fight for your impression.</p>"},{"location":"#your-formula-for-visibility","title":"Your Formula for Visibility","text":"<p>Winning your auction requires aligning budget, targets, and exceptional quality. Here is the formula to capture demand and secure top positioning:</p> <ul> <li>Uncapped Budget: Maximise your potential and ensure funds don't limit your entry into auctions.</li> <li>Unrestricted Target: Relax your CPA or ROAS goals to allow for competitive bidding.</li> <li>High Quality Score (7+): Deliver deep relevance and an outstanding user experience.</li> <li>The Result: When you combine these factors, you achieve your goal: Impression Share Won.</li> </ul>"},{"location":"#how-arba-solves-the-problem","title":"How ARBA Solves the Problem","text":"<p>When your Quality Score is low, simply raising budgets or tweaking targets won't yield sustainable efficiency. ARBA identifies every reason your ads lose Impression Share, featuring a deep-dive focus on mastering your Quality Score. We pinpoint exactly where the problem is happening and what you can do to fix it.</p>"},{"location":"#how-arba-stands-out","title":"How ARBA Stands Out","text":"<ul> <li>Unified &amp; Shareable: Provides a fully automated, externally shareable dashboard. This offers a single view to identify all Ad Rank gaps with proactive daily or weekly updates.</li> <li>Gemini AI Powered: Leverages Gemini for deep analysis of USPs and CTAs. It also cross-checks popular keywords between your landing pages and active ads.</li> <li>QS Structure Solutions: Intelligently analyzes your account's search structure. It suggests changes to ensure keywords have sufficient data for accurate Quality Score calculation.</li> </ul>"},{"location":"#three-phases-of-optimization","title":"Three Phases of Optimization","text":"<ul> <li>Diagnostic: Analyse shifts in your spend, CPC, and impression share to detect timeline and auction changes.</li> <li>Immediate Wins: Execute fast actions to regain competitive edge, such as altering bids or increasing budgets to capture impression share.</li> <li>Quality Score: Move into deep optimization by following granular dashboard recommendations to drastically improve Ad Relevance and Landing Page Experience.</li> </ul>"},{"location":"#is-arba-right-for-you","title":"Is ARBA Right For You?","text":"<p>ARBA is the ideal solution if any of the following apply to your campaigns:</p> <ul> <li>Impression Share is a Key Metric: You actively track Impression Share and Top Impression Share as primary KPIs to measure true brand visibility.</li> <li>Uncapped Potential, Low Visibility: Your account is not heavily budget or target-limited, but you still suffer from unusually low Impression Share.</li> <li>Navigating Major Account Shifts: You need a rigorous way to measure changes after significant updates, like launching fresh ad creatives, a new website, or a total account restructure.</li> <li>Defending Brand Dominance: You have active concerns about a decreasing trend in your Top Impression Share and need to protect your competitive standing.</li> </ul>"},{"location":"dashboard/replication/","title":"Dashboard Replication","text":"<p>Important</p> <p>Join <code>arba-readers-external</code> Google group  to get access to the dashboard template.</p>"},{"location":"dashboard/replication/#create-dashboard","title":"Create dashboard","text":"<p>Provide BigQuery project and dataset names where <code>arba</code> data are located.</p> <pre><code>./scripts/create_dashboard.sh -p $GOOGLE_CLOUD_PROJECT -d arba\n</code></pre>"},{"location":"installation/airflow/","title":"Apache Airflow","text":"<p>Running Arba in Apache Airflow is easy.</p> <p>You'll need to provide three arguments for running <code>DockerOperator</code> inside your DAG:</p> <ul> <li><code>/path/to/google-ads.yaml</code> - absolute path to <code>google-ads.yaml</code> file (can be remote)</li> <li><code>service_account.json</code> - absolute path to service account json file</li> </ul>"},{"location":"installation/airflow/#example-dags","title":"Example DAGs","text":""},{"location":"installation/airflow/#getting-configuration-files-locally","title":"Getting configuration files locally","text":"<p>Important</p> <p>Don't forget to change <code>/path/to/google-ads.yaml</code>, <code>path/to/service_account.json</code> valid paths.</p> <pre><code>from airflow import DAG\nfrom datetime import datetime, timedelta\nfrom airflow.providers.docker.operators.docker import DockerOperator\nfrom docker.types import Mount\n\n\ndefault_args = {\n    'description'           : 'arba',\n    'depend_on_past'        : False,\n    'start_date'            : datetime(2026, 3, 1),\n    'email_on_failure'      : False,\n    'email_on_retry'        : False,\n    'retries'               : 1,\n    'retry_delay'           : timedelta(minutes=5)\n}\nwith DAG(\n    'arba',\n    default_args=default_args,\n    schedule_interval=\"0 0 * * *\",\n    catchup=False) as dag:\n    app_reporting_pack = DockerOperator(\n      task_id='arba_docker',\n      image='ghcr.io/google-marketing-solutions/arba:latest',\n      api_version='auto',\n      auto_remove=True,\n      command=[\n        \"-c\", \"/google-ads.yaml\",\n        \"-a\", \"GOOGLE_ADS_ACCOUNT\",\n      ],\n      environment={\n        'GEMINI_API_KEY': GEMINI_API_KEY,\n        'GOOGLE_CLOUD_PROJECT': GOOGLE_CLOUD_PROJECT,\n      },\n      docker_url=\"unix://var/run/docker.sock\",\n      mounts=[\n        Mount(\n          source=\"/path/to/service_account.json\",\n          target=\"/app/service_account.json\",\n          type=\"bind\"),\n        Mount(\n          source=\"/path/to/google-ads.yaml\",\n          target=\"/google-ads.yaml\",\n          type=\"bind\"),\n      ]\n    )\n</code></pre>"},{"location":"installation/docker/","title":"Docker","text":""},{"location":"installation/docker/#prerequisites","title":"Prerequisites","text":"<ol> <li>Credentials for Google Ads API access which are stored in <code>google-ads.yaml</code>.     See details here.</li> <li>A Google Cloud project with billing account attached.</li> <li>Vertex AI API enabled.</li> <li>Environment variables specified:<ul> <li>GEMINI_API_KEY to access Google Gemini.</li> </ul> </li> <li> <p>Service account created and service account key downloaded in order to write data to BigQuery.</p> <p>Note</p> <p>If authenticating via service account is not possible you can authenticate with the following command: <pre><code>gcloud auth application-default login\n</code></pre> You can grab <code>application_default_credentials.json</code> file from <code>$HOME/.config/gcloud</code> folder.</p> </li> </ol>"},{"location":"installation/docker/#run","title":"Run","text":"<p>Map local files, provide environment variables and run</p> <pre><code>docker run \\\n  -v /path/to/google-ads.yaml:/app/google-ads.yaml \\\n  -v /path/to/application_default_credentials.json:/app/service_account.json \\\n  -e GEMINI_API_KEY=$GEMINI_API_KEY \\\n  -e GOOGLE_CLOUD_PROJECT=$GOOGLE_CLOUD_PROJECT \\\n  ghcr.io/google-marketing-solutions/arba:latest \\\n  -a &lt;GOOGLE_ADS_ACCOUNT&gt; -c /app/google-ads.yaml\n</code></pre> <p>where:</p> <ul> <li><code>-a</code> - Google Ads account(s) or MCC(s)</li> <li><code>-c</code> - Path to google-ads.yaml</li> </ul>"},{"location":"installation/docker/#customize","title":"Customize","text":"<p>You can provide the following Environment variables to customize <code>arba</code> execution.</p> <ul> <li><code>START_DATE</code> - First date of performance; can be either date (i.e. '2026-01-01') or lookback (<code>:YYYYMMDD-N</code>, where N - number of lookback days).</li> <li><code>END_DATE</code> - Last date of performance in the same format as <code>START_DATE</code>.</li> <li><code>MIN_COST_SHARE</code> - Share of text ads needs to be processed by Gemini. From 0 to 100.</li> <li><code>GEMINI_API_KEY</code> - Gemini API key.</li> </ul>"},{"location":"installation/gcp/","title":"Google Cloud Platform","text":"<p>Arba is deployed to Google Cloud as a Cloud Run job.</p> <p>During the installation the following artifacts are created:</p> <ul> <li>Cloud Run job (<code>arba</code>)</li> <li>Cloud Scheduler job (<code>arba-scheduler</code>)</li> <li>Bucket in Cloud Storage - <code>gs://PROJECT_ID/arba</code>)</li> <li>Repository in Artifact Registry - <code>google-marketing-solutions</code></li> <li>Image in the repository above - <code>arba</code></li> </ul>"},{"location":"installation/gcp/#prerequisites","title":"Prerequisites","text":"<ol> <li>Credentials for Google Ads API access which stored in <code>google-ads.yaml</code>.     See details here.</li> <li>A Google Cloud project with billing account attached.</li> <li>Vertex AI API enabled.</li> <li>Environment variables specified:<ul> <li>GEMINI_API_KEY to access Google Gemini.</li> </ul> </li> </ol>"},{"location":"installation/gcp/#install","title":"Install","text":"<ol> <li> <p>Clone repo in Cloud Shell or on your local machine (we assume Linux with <code>gcloud</code> CLI installed):</p> <pre><code>git clone https://github.com/google-marketing-solutions/arba.git\n</code></pre> </li> <li> <p>Go to the repo folder: <code>cd arba/</code></p> </li> <li> <p>Put your <code>google-ads.yaml</code> there.</p> </li> <li> <p>Deploy</p> </li> </ol> <pre><code>./deploy.sh\n</code></pre>"},{"location":"installation/gcp/#customize","title":"Customize","text":"<p><code>arba</code> is deployed as a Cloud Run job with name <code>arba</code>.</p> <p>You can customize the following options of the job.</p> <p>In Google Cloud go to <code>Cloud Run -&gt; Jobs -&gt; arba</code>, click on <code>View &amp; edit job configuration</code>, scroll to <code>Containers, Connection, Security</code>, select <code>Variables &amp; Secrets</code> and adjust one of the following Environment variables:</p> <ul> <li><code>BQ_DATASET</code> - BigQuery dataset where data are saved.</li> <li><code>ACCOUNT</code> - Google Ads account(s) or MCC(s).</li> <li><code>ADS_CONFIG</code> - Path to google-ads.yaml on Google Cloud Storage.</li> <li><code>START_DATE</code> - First date of performance; can be either date (i.e. '2026-01-01') or lookback (<code>:YYYYMMDD-N</code>, where N - number of lookback days).</li> <li><code>END_DATE</code> - Last date of performance in the same format as <code>START_DATE</code>.</li> <li><code>MIN_COST_SHARE</code> - Share of text ads needs to be processed by Gemini. From 0 to 100.</li> <li><code>GEMINI_API_KEY</code> - Gemini API key.</li> </ul> <p>By default <code>arba</code> is scheduled to run on midnight UTC. You can change the schedule in Cloud Scheduler. Locate <code>arba-scheduler</code> and define your own schedule.</p>"},{"location":"installation/gcp/#upgrade","title":"Upgrade","text":"<p>Upgrade makes new queries and dependencies available.</p> <pre><code>./upgrade.sh\n</code></pre>"},{"location":"installation/gcp/#uninstall","title":"Uninstall","text":"<p>Uninstall removes Arba Cloud Storage bucket, docker image, Cloud Run Job and Cloud Scheduler only. You need to remove BigQuery dataset manually.</p> <pre><code>./uninstall.sh\n</code></pre>"},{"location":"installation/local/","title":"Local Installation","text":""},{"location":"installation/local/#prerequisites","title":"Prerequisites","text":"<ol> <li>Credentials for Google Ads API access which are stored in <code>google-ads.yaml</code>.     See details here.</li> <li>A Google Cloud project with billing account attached.</li> <li>Vertex AI API enabled.</li> <li>Environment variables specified:<ul> <li>GEMINI_API_KEY to access Google Gemini.</li> </ul> </li> <li> <p>Service account created and service account key downloaded in order to write data to BigQuery.</p> <ul> <li>Expose <code>GOOGLE_APPLICATION_CREDENTIALS</code> variable that points to this service account JSON file.</li> </ul> <p>Note</p> <p>If authenticating via service account is not possible you can authenticate with the following command: <pre><code>gcloud auth application-default login\n</code></pre> You can grab <code>application_default_credentials.json</code> file from <code>$HOME/.config/gcloud</code> folder.</p> </li> </ol>"},{"location":"installation/local/#install","title":"Install","text":"<pre><code>pip install -r requirements.txt\n</code></pre>"},{"location":"installation/local/#run","title":"Run","text":"<ol> <li>Provide default values in <code>workflow-config.yaml</code><ul> <li><code>bq_project</code> - name of Google Cloud Project.</li> <li><code>google_ads_account</code> - ID(s) of Google Ads accounts.</li> </ul> </li> </ol> <p>Note</p> <p>Optionally you can provide other parameters:</p> <ul> <li><code>bq_dataset</code> - name of BigQuery dataset where the AdRank Booster data to be stored (by default <code>arba</code>).</li> <li><code>google_ads_config</code> -  path to <code>google-ads.yaml</code> file (by default expected in your home directory).</li> </ul> <ol> <li>Run the following command to start generating data:</li> </ol> <pre><code>garf -w workflow-config.yaml\n</code></pre>"},{"location":"installation/overview/","title":"Overview","text":"<p>There are several ways to install the ARBA.</p> <ul> <li> Google Cloud Recommended</li> <li> Docker</li> <li> Airflow</li> <li> Local</li> </ul>"}]}